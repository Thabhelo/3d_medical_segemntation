{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unified Experiments Runner (Colab-ready)\n",
    "\n",
    "This notebook sets up the environment (Colab or local) and runs all experiment combinations across datasets and architectures.\n",
    "\n",
    "- Datasets: BraTS, MSD Liver, TotalSegmentator\n",
    "- Architectures: UNet, UNETR, SegResNet\n",
    "\n",
    "If running on Colab, it mounts Google Drive and installs requirements. Use the runner cell to execute all combinations or adjust selections.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detect Colab and optionally mount Google Drive\n",
    "IN_COLAB = False\n",
    "try:\n",
    "    import google.colab  # type: ignore\n",
    "    IN_COLAB = True\n",
    "except Exception:\n",
    "    IN_COLAB = False\n",
    "\n",
    "print(f\"Running in Colab: {IN_COLAB}\")\n",
    "\n",
    "if IN_COLAB:\n",
    "    from google.colab import drive  # type: ignore\n",
    "    drive.mount('/content/drive')\n",
    "\n",
    "# Ensure correct working directory when cloned in Colab\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import subprocess\n",
    "\n",
    "if IN_COLAB:\n",
    "    # Support current repo name (typo) and future corrected name\n",
    "    candidates = [\n",
    "        (\n",
    "            Path('/content/3d_medical_segemntation'),\n",
    "            'https://github.com/thabhelo/3d_medical_segemntation.git'\n",
    "        ),\n",
    "        (\n",
    "            Path('/content/3d_medical_segmentation'),\n",
    "            'https://github.com/thabhelo/3d_medical_segmentation.git'\n",
    "        ),\n",
    "    ]\n",
    "\n",
    "    # Use existing clone if present; otherwise try cloning candidates in order\n",
    "    repo_dir = None\n",
    "    for path, url in candidates:\n",
    "        if path.exists():\n",
    "            repo_dir = path\n",
    "            break\n",
    "    if repo_dir is None:\n",
    "        for path, url in candidates:\n",
    "            try:\n",
    "                subprocess.run(['git','clone','-q', url, str(path)], check=True)\n",
    "                repo_dir = path\n",
    "                break\n",
    "            except Exception:\n",
    "                continue\n",
    "    if repo_dir is None:\n",
    "        raise RuntimeError('Failed to clone repository using known names.')\n",
    "\n",
    "    os.chdir(repo_dir)\n",
    "\n",
    "sys.path.insert(0, str(Path.cwd() / 'src'))\n",
    "print(f\"CWD: {Path.cwd()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optionally install dependencies (Colab)\n",
    "if IN_COLAB:\n",
    "    import subprocess\n",
    "    # Install minimal pinned deps; setup.sh is heavy, so install selectively for speed\n",
    "    cmds = [\n",
    "        ['pip','install','-q','torch==2.3.0','torchvision==0.18.0','--index-url','https://download.pytorch.org/whl/cu121'],\n",
    "        ['pip','install','-q','monai[all]==1.3.0','numpy==1.26.4','scipy>=1.12,<1.14'],\n",
    "        ['pip','install','-q','scikit-learn>=1.3.0','pandas>=2.0.0'],\n",
    "        ['pip','install','-q','matplotlib>=3.7.0','seaborn>=0.12.0','nibabel','SimpleITK','PyYAML','tqdm','tensorboard']\n",
    "    ]\n",
    "    for c in cmds:\n",
    "        print('Running:', ' '.join(c))\n",
    "        subprocess.run(c, check=True)\n",
    "    print('Dependencies installed.')\n",
    "else:\n",
    "    print('Local environment detected; ensure requirements are installed.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Runner: iterate over datasets x architectures\n",
    "from pathlib import Path\n",
    "import itertools\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "# Configurable selections\n",
    "DATASETS = ['brats', 'msd_liver', 'totalsegmentator']\n",
    "ARCHITECTURES = ['unet', 'unetr', 'segresnet']\n",
    "MAX_EPOCHS = 2\n",
    "BATCH_SIZE = 2\n",
    "NUM_WORKERS = 2\n",
    "OUTPUT_BASE = Path('results/colab_runs')\n",
    "\n",
    "OUTPUT_BASE.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print('Dataset root auto-detected by train_model.py based on environment.')\n",
    "\n",
    "runs = list(itertools.product(DATASETS, ARCHITECTURES))\n",
    "print(f'Total runs: {len(runs)}')\n",
    "\n",
    "for ds, arch in runs:\n",
    "    out_dir = OUTPUT_BASE / f'{ds}_{arch}'\n",
    "    cmd = [\n",
    "        sys.executable,\n",
    "        'scripts/train_model.py',\n",
    "        '--dataset', ds,\n",
    "        '--architecture', arch,\n",
    "        '--max_epochs', str(MAX_EPOCHS),\n",
    "        '--batch_size', str(BATCH_SIZE),\n",
    "        '--num_workers', str(NUM_WORKERS),\n",
    "        '--output_dir', str(out_dir)\n",
    "    ]\n",
    "    print('\\n=== Running:', ' '.join(cmd))\n",
    "    subprocess.run(cmd, check=False)\n",
    "\n",
    "print('\\nAll runs completed.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SegResNet Training Experiments\\n\n",
    "\\n\n",
    "This notebook trains the remaining SegResNet experiments:\\n\n",
    "1. SegResNet + BraTS\\n\n",
    "2. SegResNet + MSD Liver\\n\n",
    "\\n\n",
    "**Prerequisites:**\\n\n",
    "- Run `00_environment_setup.ipynb` first\\n\n",
    "- Ensure GPU is available and datasets are uploaded\\n\n",
    "\\n\n",
    "**Expected Duration:** ~45 minutes total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick verification that environment is ready\\n\n",
    "import torch\\n\n",
    "import sys\\n\n",
    "import os\\n\n",
    "from pathlib import Path\\n\n",
    "from datetime import datetime\\n\n",
    "import subprocess\\n\n",
    "\\n\n",
    "print('Pre-training verification:')\\n\n",
    "print('-' * 30)\\n\n",
    "\\n\n",
    "# Check GPU\\n\n",
    "if torch.cuda.is_available():\\n\n",
    "    print(f'GPU: {torch.cuda.get_device_name(0)}')\\n\n",
    "else:\\n\n",
    "    print('WARNING: No GPU detected - training will be slow')\\n\n",
    "\\n\n",
    "# Determine dataset path\\n\n",
    "is_colab = 'google.colab' in sys.modules or os.path.exists('/content')\\n\n",
    "datasets_root = Path('/content/drive/MyDrive/datasets' if is_colab else Path.home() / 'Downloads/datasets')\\n\n",
    "\\n\n",
    "# Check required datasets\\n\n",
    "required_datasets = ['BraTS', 'MSD']\\n\n",
    "for dataset in required_datasets:\\n\n",
    "    dataset_path = datasets_root / dataset\\n\n",
    "    print(f'{dataset}: {\\\"Available\\\" if dataset_path.exists() else \\\"MISSING\\\"}')\\n\n",
    "\\n\n",
    "print('\\nReady for SegResNet experiments!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SegResNet + BraTS Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Starting SegResNet + BraTS at {datetime.now().strftime(\\\"%H:%M:%S\\\")}')\\n\n",
    "print('Expected duration: ~20 minutes')\\n\n",
    "print('=' * 50)\\n\n",
    "\\n\n",
    "subprocess.run([\\n\n",
    "    'python', 'scripts/train_model.py',\\n\n",
    "    '--dataset', 'brats',\\n\n",
    "    '--data_root', str(datasets_root),\\n\n",
    "    '--architecture', 'segresnet',\\n\n",
    "    '--in_channels', '4',\\n\n",
    "    '--out_channels', '4',\\n\n",
    "    '--batch_size', '2',\\n\n",
    "    '--max_epochs', '100',\\n\n",
    "    '--output_dir', 'results/segresnet_brats'\\n\n",
    "], check=True)\\n\n",
    "\\n\n",
    "print('SegResNet + BraTS completed!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SegResNet + MSD Liver Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Starting SegResNet + MSD Liver at {datetime.now().strftime(\\\"%H:%M:%S\\\")}')\\n\n",
    "print('Expected duration: ~25 minutes')\\n\n",
    "print('=' * 50)\\n\n",
    "\\n\n",
    "subprocess.run([\\n\n",
    "    'python', 'scripts/train_model.py',\\n\n",
    "    '--dataset', 'msd_liver',\\n\n",
    "    '--data_root', str(datasets_root),\\n\n",
    "    '--architecture', 'segresnet',\\n\n",
    "    '--in_channels', '1',\\n\n",
    "    '--out_channels', '3',\\n\n",
    "    '--batch_size', '2',\\n\n",
    "    '--max_epochs', '100',\\n\n",
    "    '--output_dir', 'results/segresnet_msd_liver'\\n\n",
    "], check=True)\\n\n",
    "\\n\n",
    "print('SegResNet + MSD Liver completed!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check training results\\n\n",
    "results_dir = Path('results')\\n\n",
    "segresnet_experiments = ['segresnet_brats', 'segresnet_msd_liver']\\n\n",
    "\\n\n",
    "print('SegResNet Training Summary')\\n\n",
    "print('=' * 40)\\n\n",
    "\\n\n",
    "completed_count = 0\\n\n",
    "for exp in segresnet_experiments:\\n\n",
    "    exp_dir = results_dir / exp\\n\n",
    "    best_model = exp_dir / 'best.pth'\\n\n",
    "    \\n\n",
    "    if best_model.exists():\\n\n",
    "        completed_count += 1\\n\n",
    "        model_size = best_model.stat().st_size / (1024 * 1024)\\n\n",
    "        print(f'COMPLETED: {exp} ({model_size:.1f} MB)')\\n\n",
    "    else:\\n\n",
    "        print(f'NOT FOUND: {exp}')\\n\n",
    "\\n\n",
    "print(f'\\nProgress: {completed_count}/{len(segresnet_experiments)} SegResNet experiments completed')\\n\n",
    "print('Next: Run 02_train_totalsegmentator_experiments.ipynb')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
