{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unified Experiments Runner\n",
    "\n",
    "Run experiment combinations across datasets and architectures.\n",
    "\n",
    "- Datasets: BraTS, MSD Liver, TotalSegmentator\n",
    "- Architectures: UNet, UNETR, SegResNet\n",
    "\n",
    "On Colab, this notebook mounts Google Drive, installs requirements, and clones the repository. Use the runner cell to execute all combinations or adjust selections.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detect Colab and optionally mount Google Drive\n",
    "IN_COLAB = False\n",
    "try:\n",
    "    import google.colab  # type: ignore\n",
    "    IN_COLAB = True\n",
    "except Exception:\n",
    "    IN_COLAB = False\n",
    "\n",
    "print(f\"Running in Colab: {IN_COLAB}\")\n",
    "\n",
    "if IN_COLAB:\n",
    "    from google.colab import drive  # type: ignore\n",
    "    drive.mount('/content/drive')\n",
    "\n",
    "# Ensure correct working directory when cloned in Colab\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import subprocess\n",
    "from datetime import datetime\n",
    "\n",
    "if IN_COLAB:\n",
    "    # Persist repository under Drive (current name with typo)\n",
    "    repo_dir = Path('/content/drive/MyDrive/3d_medical_segemntation')\n",
    "    if not repo_dir.exists():\n",
    "        subprocess.run(['git','clone','-q','https://github.com/Thabhelo/3d_medical_segemntation.git', str(repo_dir)], check=True)\n",
    "    else:\n",
    "        # Try fast-forward; if it fails, hard reset to origin/main; if still broken, reclone\n",
    "        try:\n",
    "            subprocess.run(['git','-C', str(repo_dir), 'fetch', 'origin'], check=True)\n",
    "            subprocess.run(['git','-C', str(repo_dir), 'checkout', 'main'], check=True)\n",
    "            subprocess.run(['git','-C', str(repo_dir), 'pull', '--ff-only'], check=True)\n",
    "        except Exception:\n",
    "            try:\n",
    "                subprocess.run(['git','-C', str(repo_dir), 'reset', '--hard', 'origin/main'], check=True)\n",
    "            except Exception:\n",
    "                # Backup and reclone cleanly\n",
    "                backup = repo_dir.with_name(repo_dir.name + '_backup_' + datetime.now().strftime('%Y%m%d_%H%M%S'))\n",
    "                try:\n",
    "                    repo_dir.rename(backup)\n",
    "                except Exception:\n",
    "                    pass\n",
    "                subprocess.run(['git','clone','-q','https://github.com/Thabhelo/3d_medical_segemntation.git', str(repo_dir)], check=True)\n",
    "    os.chdir(repo_dir)\n",
    "\n",
    "sys.path.insert(0, str(Path.cwd() / 'src'))\n",
    "print(f\"CWD: {Path.cwd()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies (Colab) â€” Python 3.12 compatible\n",
    "if IN_COLAB:\n",
    "    import os, subprocess\n",
    "    cuda_idx = ['--index-url','https://download.pytorch.org/whl/cu121'] if os.path.exists('/proc/driver/nvidia') else ['--index-url','https://download.pytorch.org/whl/cpu']\n",
    "    cmds = [\n",
    "        ['pip','install','-q','--upgrade','pip','setuptools','wheel'],\n",
    "        ['pip','install','-q','torch==2.4.0','torchvision==0.19.0', *cuda_idx],\n",
    "        ['pip','install','-q','monai-weekly','numpy>=1.26.4','scipy>=1.12','nibabel','SimpleITK','PyYAML','tqdm','tensorboard','matplotlib>=3.7','seaborn>=0.12','scikit-learn>=1.3','pandas>=2.0']\n",
    "    ]\n",
    "    for c in cmds:\n",
    "        print('Running:', ' '.join(c))\n",
    "        subprocess.run(c, check=True)\n",
    "    print('Dependencies installed.')\n",
    "else:\n",
    "    print('Local environment detected; ensure requirements are installed.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick verification: environment, GPU, datasets, and repo state\n",
    "import os, sys, subprocess\n",
    "from pathlib import Path\n",
    "import torch\n",
    "\n",
    "print('Python:', sys.version.split()[0])\n",
    "print('PyTorch:', torch.__version__)\n",
    "print('CUDA available:', torch.cuda.is_available())\n",
    "if torch.cuda.is_available():\n",
    "    print('GPU:', torch.cuda.get_device_name(0))\n",
    "\n",
    "# Check datasets\n",
    "is_colab = 'google.colab' in sys.modules or os.path.exists('/content')\n",
    "DATASETS_DIR = Path('/content/drive/MyDrive/datasets' if is_colab else Path.home() / 'Downloads/datasets')\n",
    "print('Datasets dir:', DATASETS_DIR)\n",
    "for name in ['BraTS','MSD','TotalSegmentator']:\n",
    "    p = DATASETS_DIR / name\n",
    "    print(f'  {name}:', 'FOUND' if p.exists() else 'MISSING')\n",
    "\n",
    "# Show git commit and remote\n",
    "try:\n",
    "    commit = subprocess.check_output(['git','rev-parse','--short','HEAD']).decode().strip()\n",
    "    remote = subprocess.check_output(['git','remote','get-url','origin']).decode().strip()\n",
    "    print('Repo commit:', commit)\n",
    "    print('Remote:', remote)\n",
    "except Exception as e:\n",
    "    print('Git info unavailable:', e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Runner: iterate over datasets x architectures\n",
    "from pathlib import Path\n",
    "import itertools\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "# Configurable selections\n",
    "DATASETS = ['brats', 'msd_liver', 'totalsegmentator']\n",
    "ARCHITECTURES = ['unet', 'unetr', 'segresnet']\n",
    "MAX_EPOCHS = 2\n",
    "BATCH_SIZE = 2\n",
    "NUM_WORKERS = 2\n",
    "OUTPUT_BASE = Path('results/colab_runs')\n",
    "\n",
    "OUTPUT_BASE.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print('Dataset root auto-detected by train_model.py based on environment.')\n",
    "\n",
    "runs = list(itertools.product(DATASETS, ARCHITECTURES))\n",
    "print(f'Total runs: {len(runs)}')\n",
    "\n",
    "for ds, arch in runs:\n",
    "    out_dir = OUTPUT_BASE / f'{ds}_{arch}'\n",
    "    cmd = [\n",
    "        sys.executable,\n",
    "        'scripts/train_model.py',\n",
    "        '--dataset', ds,\n",
    "        '--architecture', arch,\n",
    "        '--max_epochs', str(MAX_EPOCHS),\n",
    "        '--batch_size', str(BATCH_SIZE),\n",
    "        '--num_workers', str(NUM_WORKERS),\n",
    "        '--output_dir', str(out_dir)\n",
    "    ]\n",
    "    print('\\n=== Running:', ' '.join(cmd))\n",
    "    subprocess.run(cmd, check=False)\n",
    "\n",
    "print('\\nAll runs completed.')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
