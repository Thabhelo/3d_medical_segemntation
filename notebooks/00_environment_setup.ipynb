{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SegResNet Training Experiments\\n",
    "\\n",
    "This notebook trains the remaining SegResNet experiments:\\n",
    "1. SegResNet + BraTS\\n",
    "2. SegResNet + MSD Liver\\n",
    "\\n",
    "**Prerequisites:**\\n",
    "- Run `00_environment_setup.ipynb` first\\n",
    "- Ensure GPU is available and datasets are uploaded\\n",
    "\\n",
    "**Expected Duration:** ~45 minutes total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick verification that environment is ready\\n",
    "import torch\\n",
    "import sys\\n",
    "import os\\n",
    "from pathlib import Path\\n",
    "from datetime import datetime\\n",
    "import subprocess\\n",
    "\\n",
    "print('Pre-training verification:')\\n",
    "print('-' * 30)\\n",
    "\\n",
    "# Check GPU\\n",
    "if torch.cuda.is_available():\\n",
    "    print(f'GPU: {torch.cuda.get_device_name(0)}')\\n",
    "else:\\n",
    "    print('WARNING: No GPU detected - training will be slow')\\n",
    "\\n",
    "# Determine dataset path\\n",
    "is_colab = 'google.colab' in sys.modules or os.path.exists('/content')\\n",
    "datasets_root = Path('/content/drive/MyDrive/datasets' if is_colab else Path.home() / 'Downloads/datasets')\\n",
    "\\n",
    "# Check required datasets\\n",
    "required_datasets = ['BraTS', 'MSD']\\n",
    "for dataset in required_datasets:\\n",
    "    dataset_path = datasets_root / dataset\\n",
    "    print(f'{dataset}: {\\\"Available\\\" if dataset_path.exists() else \\\"MISSING\\\"}')\\n",
    "\\n",
    "print('\\nReady for SegResNet experiments!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SegResNet + BraTS Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Starting SegResNet + BraTS at {datetime.now().strftime(\\\"%H:%M:%S\\\")}')\\n",
    "print('Expected duration: ~20 minutes')\\n",
    "print('=' * 50)\\n",
    "\\n",
    "subprocess.run([\\n",
    "    'python', 'scripts/train_model.py',\\n",
    "    '--dataset', 'brats',\\n",
    "    '--data_root', str(datasets_root),\\n",
    "    '--architecture', 'segresnet',\\n",
    "    '--in_channels', '4',\\n",
    "    '--out_channels', '4',\\n",
    "    '--batch_size', '2',\\n",
    "    '--max_epochs', '100',\\n",
    "    '--output_dir', 'results/segresnet_brats'\\n",
    "], check=True)\\n",
    "\\n",
    "print('SegResNet + BraTS completed!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SegResNet + MSD Liver Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Starting SegResNet + MSD Liver at {datetime.now().strftime(\\\"%H:%M:%S\\\")}')\\n",
    "print('Expected duration: ~25 minutes')\\n",
    "print('=' * 50)\\n",
    "\\n",
    "subprocess.run([\\n",
    "    'python', 'scripts/train_model.py',\\n",
    "    '--dataset', 'msd_liver',\\n",
    "    '--data_root', str(datasets_root),\\n",
    "    '--architecture', 'segresnet',\\n",
    "    '--in_channels', '1',\\n",
    "    '--out_channels', '3',\\n",
    "    '--batch_size', '2',\\n",
    "    '--max_epochs', '100',\\n",
    "    '--output_dir', 'results/segresnet_msd_liver'\\n",
    "], check=True)\\n",
    "\\n",
    "print('SegResNet + MSD Liver completed!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check training results\\n",
    "results_dir = Path('results')\\n",
    "segresnet_experiments = ['segresnet_brats', 'segresnet_msd_liver']\\n",
    "\\n",
    "print('SegResNet Training Summary')\\n",
    "print('=' * 40)\\n",
    "\\n",
    "completed_count = 0\\n",
    "for exp in segresnet_experiments:\\n",
    "    exp_dir = results_dir / exp\\n",
    "    best_model = exp_dir / 'best.pth'\\n",
    "    \\n",
    "    if best_model.exists():\\n",
    "        completed_count += 1\\n",
    "        model_size = best_model.stat().st_size / (1024 * 1024)\\n",
    "        print(f'COMPLETED: {exp} ({model_size:.1f} MB)')\\n",
    "    else:\\n",
    "        print(f'NOT FOUND: {exp}')\\n",
    "\\n",
    "print(f'\\nProgress: {completed_count}/{len(segresnet_experiments)} SegResNet experiments completed')\\n",
    "print('Next: Run 02_train_totalsegmentator_experiments.ipynb')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}