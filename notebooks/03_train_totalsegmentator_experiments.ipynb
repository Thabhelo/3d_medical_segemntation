{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TotalSegmentator Training Experiments\n",
    "\n",
    "This notebook trains all architectures on TotalSegmentator dataset (subset):\n",
    "1. UNet + TotalSegmentator\n",
    "2. UNETR + TotalSegmentator\n",
    "3. SegResNet + TotalSegmentator\n",
    "\n",
    "**Note:** Using subset of anatomical structures for computational feasibility.\n",
    "\n",
    "**Requirements:**\n",
    "- Google Colab with GPU runtime\n",
    "- Datasets in Google Drive at `/content/drive/MyDrive/datasets/`\n",
    "- Project cloned from GitHub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup: Mount Drive and navigate to project\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "import os\n",
    "import subprocess\n",
    "from pathlib import Path\n",
    "\n",
    "os.chdir('/content/drive/MyDrive')\n",
    "repo_url = 'https://github.com/Thabhelo/3d_medical_segemntation.git'\n",
    "repo_dir = '3d_medical_segmentation'\n",
    "\n",
    "if os.path.exists(repo_dir):\n",
    "    print('Repository exists, pulling latest changes...')\n",
    "    os.chdir(repo_dir)\n",
    "    subprocess.run(['git', 'pull'], check=True)\n",
    "else:\n",
    "    print('Cloning repository...')\n",
    "    subprocess.run(['git', 'clone', repo_url, repo_dir], check=True)\n",
    "    os.chdir(repo_dir)\n",
    "\n",
    "print(f'Working directory: {os.getcwd()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies\n",
    "subprocess.run(['pip', 'install', '-q', '--upgrade', 'pip'], check=True)\n",
    "subprocess.run(['pip', 'install', '-q', 'torch==2.3.0', 'torchvision==0.18.0'], check=True)\n",
    "subprocess.run(['pip', 'install', '-q', 'monai[all]==1.3.0'], check=True)\n",
    "subprocess.run(['pip', 'install', '-q', '-r', 'requirements.txt'], check=True)\n",
    "\n",
    "print('Dependencies installed successfully')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify GPU and datasets\n",
    "import torch\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f'GPU available: {torch.cuda.get_device_name(0)}')\n",
    "    print(f'CUDA version: {torch.version.cuda}')\n",
    "else:\n",
    "    print('WARNING: No GPU available')\n",
    "\n",
    "# Check TotalSegmentator dataset\n",
    "datasets_root = Path('/content/drive/MyDrive/datasets')\n",
    "ts_path = datasets_root / 'TotalSegmentator'\n",
    "print(f'TotalSegmentator: {\"Found\" if ts_path.exists() else \"Missing\"}')\n",
    "\n",
    "if ts_path.exists():\n",
    "    case_count = len([d for d in ts_path.iterdir() if d.is_dir()])\n",
    "    print(f'Total cases available: {case_count}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## UNet + TotalSegmentator Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train UNet on TotalSegmentator dataset\n",
    "subprocess.run([\n",
    "    'python', 'scripts/train_model.py',\n",
    "    '--dataset', 'totalsegmentator',\n",
    "    '--data_root', '/content/drive/MyDrive/datasets',\n",
    "    '--architecture', 'unet',\n",
    "    '--in_channels', '1',\n",
    "    '--out_channels', '11',  # background + 10 major structures\n",
    "    '--batch_size', '1',     # reduced for memory efficiency\n",
    "    '--max_epochs', '50',    # reduced for initial feasibility\n",
    "    '--output_dir', 'results/unet_totalsegmentator'\n",
    "], check=True)\n",
    "\n",
    "print('UNet + TotalSegmentator training completed')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## UNETR + TotalSegmentator Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train UNETR on TotalSegmentator dataset\n",
    "subprocess.run([\n",
    "    'python', 'scripts/train_model.py',\n",
    "    '--dataset', 'totalsegmentator',\n",
    "    '--data_root', '/content/drive/MyDrive/datasets',\n",
    "    '--architecture', 'unetr',\n",
    "    '--in_channels', '1',\n",
    "    '--out_channels', '11',\n",
    "    '--batch_size', '1',\n",
    "    '--max_epochs', '50',\n",
    "    '--output_dir', 'results/unetr_totalsegmentator'\n",
    "], check=True)\n",
    "\n",
    "print('UNETR + TotalSegmentator training completed')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SegResNet + TotalSegmentator Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train SegResNet on TotalSegmentator dataset\n",
    "subprocess.run([\n",
    "    'python', 'scripts/train_model.py',\n",
    "    '--dataset', 'totalsegmentator',\n",
    "    '--data_root', '/content/drive/MyDrive/datasets',\n",
    "    '--architecture', 'segresnet',\n",
    "    '--in_channels', '1',\n",
    "    '--out_channels', '11',\n",
    "    '--batch_size', '1',\n",
    "    '--max_epochs', '50',\n",
    "    '--output_dir', 'results/segresnet_totalsegmentator'\n",
    "], check=True)\n",
    "\n",
    "print('SegResNet + TotalSegmentator training completed')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Status Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check all training results\n",
    "results_dir = Path('results')\n",
    "all_experiments = [\n",
    "    'unet_brats', 'unet_msd_liver', 'unet_totalsegmentator',\n",
    "    'unetr_brats', 'unetr_msd_liver', 'unetr_totalsegmentator',\n",
    "    'segresnet_brats', 'segresnet_msd_liver', 'segresnet_totalsegmentator'\n",
    "]\n",
    "\n",
    "print('Complete Training Status:')\n",
    "print('=' * 50)\n",
    "\n",
    "completed_count = 0\n",
    "for exp in all_experiments:\n",
    "    exp_dir = results_dir / exp\n",
    "    best_model = exp_dir / 'best.pth'\n",
    "    \n",
    "    if best_model.exists():\n",
    "        completed_count += 1\n",
    "        print(f'COMPLETED: {exp}')\n",
    "    else:\n",
    "        print(f'NOT FOUND: {exp}')\n",
    "\n",
    "print(f'\\nProgress: {completed_count}/{len(all_experiments)} experiments completed')\n",
    "\n",
    "if completed_count == len(all_experiments):\n",
    "    print('\\nAll experiments completed! Ready for results analysis and final report.')\n",
    "else:\n",
    "    remaining = len(all_experiments) - completed_count\n",
    "    print(f'\\n{remaining} experiments remaining.')"
   ]
  }
 ],\n",
 \"metadata\": {\n",
  \"kernelspec\": {\n",
   \"display_name\": \"Python 3\",\n",
   \"language\": \"python\",\n",
   \"name\": \"python3\"\n",
  },\n",
  \"language_info\": {\n",
   \"codemirror_mode\": {\n",
    \"name\": \"ipython\",\n",
    \"version\": 3\n",
   },\n",
   \"file_extension\": \".py\",\n",
   \"mimetype\": \"text/x-python\",\n",
   \"name\": \"python\",\n",
   \"nbconvert_exporter\": \"python\",\n",
   \"pygments_lexer\": \"ipython3\",\n,
   \"version\": \"3.8.10\"\n,
  }\n,
 },\n,
 \"nbformat\": 4,\n,
 \"nbformat_minor\": 4\n,
}