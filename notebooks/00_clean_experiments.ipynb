{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 3D Medical Segmentation Experiments\n\n",
        "Clean implementation with 9 separate cells for each dataset-architecture combination.\n\n",
        "## Datasets:\n",
        "- **BraTS**: 4 classes (background, NCR/NET, ED, ET)\n",
        "- **MSD Liver**: 3 classes (background, liver, tumor) - with performance optimizations\n",
        "- **TotalSegmentator**: 118 classes (background + 117 anatomical structures)\n\n",
        "## Architectures:\n",
        "- **UNet**: Basic 3D U-Net\n",
        "- **UNETR**: Vision Transformer-based\n",
        "- **SegResNet**: ResNet-based segmentation\n\n",
        "## Configuration:\n",
        "- **50 epochs** with dynamic learning rate scheduling\n",
        "- **Save every epoch** for better recovery\n",
        "- **MSD Liver**: Optimized with foreground sampling and class-balanced loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Setup: Mount Drive, Clone Repository, Install Dependencies\n",
        "import os\n",
        "import sys\n",
        "import subprocess\n",
        "from pathlib import Path\n",
        "\n",
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Clone repository\n",
        "repo_dir = Path('/content/drive/MyDrive/3d_medical_segemntation')\n",
        "if not repo_dir.exists():\n",
        "    subprocess.run(['git', 'clone', 'https://github.com/Thabhelo/3d_medical_segemntation.git', str(repo_dir)], check=True)\n",
        "else:\n",
        "    subprocess.run(['git', '-C', str(repo_dir), 'pull'], check=True)\n",
        "\n",
        "os.chdir(repo_dir)\n",
        "print(f\"Working directory: {Path.cwd()}\")\n",
        "\n",
        "# Install dependencies\n",
        "subprocess.run(['pip', 'install', '-q', 'torch==2.4.0', 'torchvision==0.19.0', '--index-url', 'https://download.pytorch.org/whl/cu121'], check=True)\n",
        "subprocess.run(['pip', 'install', '-q', 'monai-weekly', 'numpy>=1.26.4', 'scipy>=1.12', 'nibabel', 'SimpleITK', 'PyYAML', 'tqdm', 'tensorboard', 'matplotlib>=3.7', 'seaborn>=0.12', 'scikit-learn>=1.3', 'pandas>=2.0'], check=True)\n",
        "\n",
        "print(\"Setup complete!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## BraTS Dataset Experiments"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# BraTS + UNet\n",
        "import subprocess\n",
        "import sys\n",
        "\n",
        "print(\"Training: BraTS + UNet\")\n",
        "print(\"Expected time: ~15 minutes (50 epochs with dynamic LR)\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "result = subprocess.run([\n",
        "    sys.executable, '-u', 'scripts/train_model.py',",
        "    '--dataset', 'brats',",
        "    '--architecture', 'unet',",
        "    '--in_channels', '4',",
        "    '--out_channels', '4',",
        "    '--max_epochs', '50',",
        "    '--batch_size', '2',",
        "    '--num_workers', '2',",
        "    '--scheduler', 'reduce_on_plateau',",
        "    '--save_every_epoch',",
        "    '--output_dir', 'results/colab_runs/brats_unet'",
        "], capture_output=False, text=True)\n",
        "\n",
        "print(f\"\\nBraTS + UNet completed with exit code: {result.returncode}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# BraTS + UNETR\n",
        "import subprocess\n",
        "import sys\n",
        "\n",
        "print(\"Training: BraTS + UNETR\")\n",
        "print(\"Expected time: ~15 minutes (50 epochs with dynamic LR)\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "result = subprocess.run([\n",
        "    sys.executable, '-u', 'scripts/train_model.py',",
        "    '--dataset', 'brats',",
        "    '--architecture', 'unetr',",
        "    '--in_channels', '4',",
        "    '--out_channels', '4',",
        "    '--max_epochs', '50',",
        "    '--batch_size', '2',",
        "    '--num_workers', '2',",
        "    '--scheduler', 'reduce_on_plateau',",
        "    '--save_every_epoch',",
        "    '--output_dir', 'results/colab_runs/brats_unetr'",
        "], capture_output=False, text=True)\n",
        "\n",
        "print(f\"\\nBraTS + UNETR completed with exit code: {result.returncode}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# BraTS + SegResNet\n",
        "import subprocess\n",
        "import sys\n",
        "\n",
        "print(\"Training: BraTS + SegResNet\")\n",
        "print(\"Expected time: ~15 minutes (50 epochs with dynamic LR)\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "result = subprocess.run([\n",
        "    sys.executable, '-u', 'scripts/train_model.py',",
        "    '--dataset', 'brats',",
        "    '--architecture', 'segresnet',",
        "    '--in_channels', '4',",
        "    '--out_channels', '4',",
        "    '--max_epochs', '50',",
        "    '--batch_size', '2',",
        "    '--num_workers', '2',",
        "    '--scheduler', 'reduce_on_plateau',",
        "    '--save_every_epoch',",
        "    '--output_dir', 'results/colab_runs/brats_segresnet'",
        "], capture_output=False, text=True)\n",
        "\n",
        "print(f\"\\nBraTS + SegResNet completed with exit code: {result.returncode}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## MSD Liver Dataset Experiments (Optimized)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# MSD Liver + UNet (Optimized)\n",
        "import subprocess\n",
        "import sys\n",
        "\n",
        "print(\"Training: MSD Liver + UNet (Optimized)\")\n",
        "print(\"Expected time: ~30-40 minutes (50 epochs with dynamic LR)\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "result = subprocess.run([\n",
        "    sys.executable, '-u', 'scripts/train_msd_liver_improved.py',",
        "    '--architecture', 'unet',",
        "    '--max_epochs', '50',",
        "    '--batch_size', '2',",
        "    '--num_workers', '2',",
        "    '--lr', '1e-4',",
        "    '--scheduler', 'reduce_on_plateau',",
        "    '--output_dir', 'results/colab_runs/msd_liver_unet'",
        "], capture_output=False, text=True)\n",
        "\n",
        "print(f\"\\nMSD Liver + UNet (Optimized) completed with exit code: {result.returncode}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# MSD Liver + UNETR (Optimized)\n",
        "import subprocess\n",
        "import sys\n",
        "\n",
        "print(\"Training: MSD Liver + UNETR (Optimized)\")\n",
        "print(\"Expected time: ~30-40 minutes (50 epochs with dynamic LR)\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "result = subprocess.run([\n",
        "    sys.executable, '-u', 'scripts/train_msd_liver_improved.py',",
        "    '--architecture', 'unetr',",
        "    '--max_epochs', '50',",
        "    '--batch_size', '2',",
        "    '--num_workers', '2',",
        "    '--lr', '1e-4',",
        "    '--scheduler', 'reduce_on_plateau',",
        "    '--output_dir', 'results/colab_runs/msd_liver_unetr'",
        "], capture_output=False, text=True)\n",
        "\n",
        "print(f\"\\nMSD Liver + UNETR (Optimized) completed with exit code: {result.returncode}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# MSD Liver + SegResNet (Optimized)\n",
        "import subprocess\n",
        "import sys\n",
        "\n",
        "print(\"Training: MSD Liver + SegResNet (Optimized)\")\n",
        "print(\"Expected time: ~30-40 minutes (50 epochs with dynamic LR)\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "result = subprocess.run([\n",
        "    sys.executable, '-u', 'scripts/train_msd_liver_improved.py',",
        "    '--architecture', 'segresnet',",
        "    '--max_epochs', '50',",
        "    '--batch_size', '2',",
        "    '--num_workers', '2',",
        "    '--lr', '1e-4',",
        "    '--scheduler', 'reduce_on_plateau',",
        "    '--output_dir', 'results/colab_runs/msd_liver_segresnet'",
        "], capture_output=False, text=True)\n",
        "\n",
        "print(f\"\\nMSD Liver + SegResNet (Optimized) completed with exit code: {result.returncode}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## TotalSegmentator Dataset Experiments"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TotalSegmentator + UNet\n",
        "import subprocess\n",
        "import sys\n",
        "\n",
        "print(\"Training: TotalSegmentator + UNet\")\n",
        "print(\"Expected time: ~40-50 minutes (50 epochs with dynamic LR)\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "result = subprocess.run([\n",
        "    sys.executable, '-u', 'scripts/train_model.py',",
        "    '--dataset', 'totalsegmentator',",
        "    '--architecture', 'unet',",
        "    '--in_channels', '1',",
        "    '--out_channels', '118',",
        "    '--data_root', '/content/drive/MyDrive/datasets/TotalSegmentator',",
        "    '--max_epochs', '50',",
        "    '--batch_size', '2',",
        "    '--num_workers', '2',",
        "    '--scheduler', 'reduce_on_plateau',",
        "    '--save_every_epoch',",
        "    '--output_dir', 'results/colab_runs/totalsegmentator_unet'",
        "], capture_output=False, text=True)\n",
        "\n",
        "print(f\"\\nTotalSegmentator + UNet completed with exit code: {result.returncode}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TotalSegmentator + UNETR\n",
        "import subprocess\n",
        "import sys\n",
        "\n",
        "print(\"Training: TotalSegmentator + UNETR\")\n",
        "print(\"Expected time: ~40-50 minutes (50 epochs with dynamic LR)\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "result = subprocess.run([\n",
        "    sys.executable, '-u', 'scripts/train_model.py',",
        "    '--dataset', 'totalsegmentator',",
        "    '--architecture', 'unetr',",
        "    '--in_channels', '1',",
        "    '--out_channels', '118',",
        "    '--data_root', '/content/drive/MyDrive/datasets/TotalSegmentator',",
        "    '--max_epochs', '50',",
        "    '--batch_size', '2',",
        "    '--num_workers', '2',",
        "    '--scheduler', 'reduce_on_plateau',",
        "    '--save_every_epoch',",
        "    '--output_dir', 'results/colab_runs/totalsegmentator_unetr'",
        "], capture_output=False, text=True)\n",
        "\n",
        "print(f\"\\nTotalSegmentator + UNETR completed with exit code: {result.returncode}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TotalSegmentator + SegResNet\n",
        "import subprocess\n",
        "import sys\n",
        "\n",
        "print(\"Training: TotalSegmentator + SegResNet\")\n",
        "print(\"Expected time: ~40-50 minutes (50 epochs with dynamic LR)\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "result = subprocess.run([\n",
        "    sys.executable, '-u', 'scripts/train_model.py',",
        "    '--dataset', 'totalsegmentator',",
        "    '--architecture', 'segresnet',",
        "    '--in_channels', '1',",
        "    '--out_channels', '118',",
        "    '--data_root', '/content/drive/MyDrive/datasets/TotalSegmentator',",
        "    '--max_epochs', '50',",
        "    '--batch_size', '2',",
        "    '--num_workers', '2',",
        "    '--scheduler', 'reduce_on_plateau',",
        "    '--save_every_epoch',",
        "    '--output_dir', 'results/colab_runs/totalsegmentator_segresnet'",
        "], capture_output=False, text=True)\n",
        "\n",
        "print(f\"\\nTotalSegmentator + SegResNet completed with exit code: {result.returncode}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Evaluation and Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Evaluate all trained models\n",
        "import subprocess\n",
        "import sys\n",
        "import json\n",
        "from pathlib import Path\n",
        "\n",
        "print(\"Evaluating all trained models...\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "result = subprocess.run([\n",
        "    sys.executable, '-u', 'scripts/evaluate_models.py'\n",
        "], capture_output=False, text=True)\n",
        "\n",
        "print(f\"\\nEvaluation completed with exit code: {result.returncode}\")\n",
        "\n",
        "# Display results\n",
        "results_file = Path('results/evaluation_results.json')\n",
        "if results_file.exists():\n",
        "    with open(results_file) as f:\n",
        "        results = json.load(f)\n",
        "    \n",
        "    print('\\nFinal Results:')\n",
        "    print('=' * 40)\n",
        "    for dataset, archs in results.items():\n",
        "        print(f'\\n{dataset.upper()}:')\n",
        "        for arch, metrics in archs.items():\n",
        "            dice = metrics.get('val_dice', 'N/A')\n",
        "            print(f'  {arch}: Dice = {dice}')\n",
        "else:\n",
        "    print('Results file not found.')"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}